{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vector Space Model",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrisSandy/InformationRetrieval/blob/master/Vector_Space_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "oGS3stcBUQIe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Vector Space Model"
      ]
    },
    {
      "metadata": {
        "id": "GzuZlYE4FZx3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Background"
      ]
    },
    {
      "metadata": {
        "id": "LB4-ZiMOhZvN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Models\n",
        "\n",
        "There are different models available for Information Retrieval. Some of them are shown below\n",
        "\n",
        "\n",
        "* **Boolean Model: ** In this model, terms in the document collection are represented by 1s and 0s indicating presence or absence of the term in a document. To retrieve informtion for a query string, boolean operations are done against each query term in the term-document matrix to select the documents that contain the query words.\n",
        "* **Vector Space Model:** In this model, each document is represented as a vector in a n-dimentional space with each term representing a dimention. User queries are represented in the same way in the space. Similarity of the documents and the query are calculated to rank the documents in order of relavence to retrieve them.\n",
        "\n",
        "\n",
        "#### Weighting Schemes\n",
        "\n",
        "Weights are given to terms in the document to represent the importance of the term in the documents. Some of the weighting schemes are \n",
        "\n",
        "\n",
        "\n",
        "*   TF-IDF (Term Frequency - Inverse Document Frequency)\n",
        "*   BM25/Okapi\n",
        "* Pivoted Normalisation\n",
        "\n",
        "\n",
        "In this assignment, I will be using Vector Space Model and TF-IDF weighting scheme to find and rank the document in terms of similarity.\n"
      ]
    },
    {
      "metadata": {
        "id": "U_2bPqDrMdI9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Document and Query Representation"
      ]
    },
    {
      "metadata": {
        "id": "b4epXfIfUaO_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below are the document set and the query for which the documents should be ranked\n",
        "\n",
        "#### Documents\n",
        "\n",
        "D1: Shipment of gold damaged in a fire\n",
        "\n",
        "D2: Delivery of silver arrived in a silver truck\n",
        "\n",
        "D3: Shipment of gold arrived in a truck\n",
        "\n",
        "#### Query \n",
        "\n",
        "Q:  gold silver truck.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "68QGh0EwNKOJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Calculate Weights"
      ]
    },
    {
      "metadata": {
        "id": "sEBguheyZTUk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Pre processing\n",
        "\n",
        "All the given documents are preprocessed by\n",
        "\n",
        "\n",
        "\n",
        "1.   Converting the case to lower\n",
        "2.   Removing stopwords\n"
      ]
    },
    {
      "metadata": {
        "id": "M7dKvyIISudC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Term Frequency table and Inverse Document Frequency\n",
        "\n",
        "> **TF** = Number of times term t appears in a document.\n",
        "\n",
        "Term frequency of the given documents are as shown below"
      ]
    },
    {
      "metadata": {
        "id": "VCjPV9JuNnLN",
        "colab_type": "code",
        "outputId": "5685648e-71dd-4e01-a165-949228036040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>truck</th>\n",
              "      <th>gold</th>\n",
              "      <th>fire</th>\n",
              "      <th>delivery</th>\n",
              "      <th>silver</th>\n",
              "      <th>arrived</th>\n",
              "      <th>shipment</th>\n",
              "      <th>damaged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    truck  gold  fire  delivery  silver  arrived  shipment  damaged\n",
              "d1    0.0   1.0   1.0       0.0     0.0      0.0       1.0      1.0\n",
              "d2    1.0   0.0   0.0       1.0     2.0      1.0       0.0      0.0\n",
              "d3    1.0   1.0   0.0       0.0     0.0      1.0       1.0      0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "CuvkyugkNhkS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Inverse Document Frequency\n",
        "\n",
        ">** IDF ** = log(N/n)\n",
        "\n",
        "> *where 'N' is total number of documents in the collection and 'n' is number of documents that contain term t*\n",
        "\n",
        "For Example: IDF for term 'fire' is calculated as below\n",
        "\n",
        "N = 3\n",
        "\n",
        "n = 1 (as it appeared in 1 document).\n",
        "\n",
        "**IDF = log(3/1) = 0.477**\n",
        "\n",
        "Computing the IDF for rest of the terms in similar fashion, IDF table will be as shown below"
      ]
    },
    {
      "metadata": {
        "id": "ULVVNLp_OE8U",
        "colab_type": "code",
        "outputId": "450f1087-7115-4660-81ce-8a8759690c11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "cell_type": "code",
      "source": [
        "idf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>truck</th>\n",
              "      <th>gold</th>\n",
              "      <th>fire</th>\n",
              "      <th>delivery</th>\n",
              "      <th>silver</th>\n",
              "      <th>arrived</th>\n",
              "      <th>shipment</th>\n",
              "      <th>damaged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>idf</th>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.477121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        truck      gold      fire  delivery    silver   arrived  shipment  \\\n",
              "idf  0.176091  0.176091  0.477121  0.477121  0.477121  0.176091  0.176091   \n",
              "\n",
              "      damaged  \n",
              "idf  0.477121  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "c95E5bRCO5LH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Normalising TF\n",
        "\n",
        "Term Frequencies should be normalised because number of times a term occured doesn't truely increase the significance of the term to the times it occured.\n",
        "\n",
        "I will be using sublinear scaling technique to normalise tf\n",
        "\n",
        "$wf_{i,d} =\n",
        "  \\begin{cases}\n",
        "    1+\\log(tf_{i,d})       & \\quad \\text{if } tf_{i,d} > 0\\\\\n",
        "    0  & \\quad \\text{otherwise}\n",
        "  \\end{cases}\n",
        "$\n",
        "\n",
        "For example normalised tf for term 'silver' in d2 is calculated as below \n",
        "\n",
        "**wj = 1+log(2) = 1.30**"
      ]
    },
    {
      "metadata": {
        "id": "_4mQQpaUTCD1",
        "colab_type": "code",
        "outputId": "5c86d177-70b0-4952-dce5-7fbaaeaaa255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "tf_norm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>truck</th>\n",
              "      <th>gold</th>\n",
              "      <th>fire</th>\n",
              "      <th>delivery</th>\n",
              "      <th>silver</th>\n",
              "      <th>arrived</th>\n",
              "      <th>shipment</th>\n",
              "      <th>damaged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.30103</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    truck  gold  fire  delivery   silver  arrived  shipment  damaged\n",
              "d1    0.0   1.0   1.0       0.0  0.00000      0.0       1.0      1.0\n",
              "d2    1.0   0.0   0.0       1.0  1.30103      1.0       0.0      0.0\n",
              "d3    1.0   1.0   0.0       0.0  0.00000      1.0       1.0      0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "AyCFdXOEs5l8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Weights\n",
        "\n",
        "Weights of each term in the document is calculated by multiplying TF (normalized) and IDF\n",
        "\n",
        "$w_{i,j} = TF*IDF = f_{i,j} * log(\\frac{N}{n})$\n",
        "\n",
        "$f_{i,j}$ is normalised term frequency\n",
        "\n",
        "For Example, weight of term 'fire' in d1 is calculated as below\n",
        "\n",
        "**w = 1 * 0.477 = 0.477** "
      ]
    },
    {
      "metadata": {
        "id": "fZNo0G-bUAwB",
        "colab_type": "code",
        "outputId": "503c3130-4333-479a-d3cc-abca24046adc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "dw"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>truck</th>\n",
              "      <th>gold</th>\n",
              "      <th>fire</th>\n",
              "      <th>delivery</th>\n",
              "      <th>silver</th>\n",
              "      <th>arrived</th>\n",
              "      <th>shipment</th>\n",
              "      <th>damaged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.477121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.620749</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       truck      gold      fire  delivery    silver   arrived  shipment  \\\n",
              "d1  0.000000  0.176091  0.477121  0.000000  0.000000  0.000000  0.176091   \n",
              "d2  0.176091  0.000000  0.000000  0.477121  0.620749  0.176091  0.000000   \n",
              "d3  0.176091  0.176091  0.000000  0.000000  0.000000  0.176091  0.176091   \n",
              "\n",
              "     damaged  \n",
              "d1  0.477121  \n",
              "d2  0.000000  \n",
              "d3  0.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "y9KnUyZ3xu9G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Query Weights\n",
        "\n",
        "For Query weights, less credence has been give to tf-idf and a default value of 0.5 is considered."
      ]
    },
    {
      "metadata": {
        "id": "evq-U0BJUz8t",
        "colab_type": "code",
        "outputId": "d07c79d6-fd87-4dc4-9ba5-eb5cbd113bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "cell_type": "code",
      "source": [
        "qw"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>truck</th>\n",
              "      <th>gold</th>\n",
              "      <th>fire</th>\n",
              "      <th>delivery</th>\n",
              "      <th>silver</th>\n",
              "      <th>arrived</th>\n",
              "      <th>shipment</th>\n",
              "      <th>damaged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>q</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   truck  gold  fire  delivery  silver  arrived  shipment  damaged\n",
              "q    0.5   0.5   0.0       0.0     0.5      0.0       0.0      0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "TFrOWSDaVreD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Calculating Similarity"
      ]
    },
    {
      "metadata": {
        "id": "0IzySfmOVGHc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As the documents and query are represented as vectors in n-dimentional space, similarity of a document and a query is calculated by calculating the cosine of the angle between the document and the query\n",
        "\n",
        "$sim(\\overrightarrow{d_j}, \\overrightarrow{q}) = \\frac{d_j\\bullet{q}}{|d_j||q|} = \\frac{\\displaystyle\\sum_{i=1}^n(w_{i,j}*w_{i,q})}{\\sqrt{\\displaystyle\\sum_{i=1}^{n}w_{i,j}^2}\\sqrt{\\displaystyle\\sum_{i=1}^{n}w_{i,q}^2}}$\n",
        "\n",
        "For Example similarity between document d1 and q is calculated as below\n",
        "\n",
        "$sim(d1,q) = \\frac{(0.176*0.5)}{\\sqrt{0.176^2 + 0.176^2+0.477^2+0.477^2}\\sqrt{0.5^2+0.5^2+0.5^2}} = 0.141$"
      ]
    },
    {
      "metadata": {
        "id": "wgODBASvTnTl",
        "colab_type": "code",
        "outputId": "325f1a03-efb5-4edd-d656-c85b559d6976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Similarity between d1 and q is {}\".format(similarity(qw.loc[q_row], dw.loc['d1'])))\n",
        "print(\"Similarity between d2 and q is {}\".format(similarity(qw.loc[q_row], dw.loc['d2'])))\n",
        "print(\"Similarity between d3 and q is {}\".format(similarity(qw.loc[q_row], dw.loc['d3'])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity between d1 and q is 0.14135252212346566\n",
            "Similarity between d2 and q is 0.5599663010899988\n",
            "Similarity between d3 and q is 0.5773502691896257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FCkKEq-JxkAg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the above similarity scores, the documents are ranked as d3, d2, d1.\n",
        "\n",
        "The similarty scores of d2 and d3 also almost same. The result depends on the various factors like\n",
        "\n",
        "\n",
        "1.   **Default Query Weights**: In this example, query weights has been taken as constant values. Some other variations include considering the idf value (e.g. $\\alpha + \\beta(idf)$ where $\\alpha, \\beta$ are the tuning parameters)\n",
        "2.   **Normalisation**: Normalisation menthods used have slight impact on the document weights and hence the similarity score. In the example, using tf without normalisation will result in document d2 ranked higher than document d3.\n",
        "3. **Sophisticated Weighting Schemes**: More sophisticated weighing schemes like BM25 will have impact on the document weights and hence on the similarity score \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vSagsiGP0dp-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Similarity Calculation"
      ]
    },
    {
      "metadata": {
        "id": "ML_xTubT5sNG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As the document d1 is changed in each of the case, Term Frequency and weights needs to be recalculated. IDF will remain the same\n",
        "\n",
        "Similarity score will need to be recalculated as well and the new similarity score between d1 and q is as below"
      ]
    },
    {
      "metadata": {
        "id": "ettT3adWYogp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### a) D1 = Shipment of gold damaged in a fire. Fire."
      ]
    },
    {
      "metadata": {
        "id": "gzxMZxZj0rSO",
        "colab_type": "code",
        "outputId": "8165c7e7-f455-407b-b402-bad4cb1b43d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "d1 = \"Shipment of gold damaged in a fire. Fire.\"\n",
        "print(recalculate_similarity([d1,d2,d3], 'd1'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.12374520733918673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eCF2Ep6QZAcF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Similarity between the document d1 and query decreased from 0.141 to 0.123 by adding a non relavent term to the document d1.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "oiF067tPZKZ-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### b) D1 = Shipment of gold damaged in a fire. Fire. Fire."
      ]
    },
    {
      "metadata": {
        "id": "_BduGV5l6L-A",
        "colab_type": "code",
        "outputId": "df08b5c4-c319-4b45-d762-f7b0f74a8741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "d1 = \"Shipment of gold damaged in a fire. Fire. Fire. \"\n",
        "print(recalculate_similarity([d1,d2,d3], 'd1'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.11464828710168476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2j_i8Udobwe-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Similarity between the document d1 and query further decreased from 0.141 to 0.114 by adding two non relavent terms to the document. As the number of non relavent terms increase in the document, the similary between the document and query will reduce."
      ]
    },
    {
      "metadata": {
        "id": "MTdvpYBvcN5i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### c) D1 = Shipment of gold damaged in a fire. Gold."
      ]
    },
    {
      "metadata": {
        "id": "tdk42Cru7C4t",
        "colab_type": "code",
        "outputId": "810906d7-b4c4-47d2-d21a-abdc9e6f941b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "d1 = \"Shipment of gold damaged in a fire. Gold. \"\n",
        "print(recalculate_similarity([d1,d2,d3], 'd1'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.18020091957864967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "28yNwc9Lcf-E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Similarity between the document d1 and query increased  from 0.141 to 0.180  by adding a relavent term to the document."
      ]
    },
    {
      "metadata": {
        "id": "EfpB1KJDco9T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### d) D1 = Shipment of gold damaged in a fire. Gold. Gold."
      ]
    },
    {
      "metadata": {
        "id": "vPKLRiGR7EHZ",
        "colab_type": "code",
        "outputId": "89ebaae4-7c17-4c39-c50e-706f48dc15b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "d1 = \"Shipment of gold damaged in a fire. Gold. Gold. \"\n",
        "print(recalculate_similarity([d1,d2,d3], 'd1'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.20176998483273476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qA_uCJG2cucj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Similarity between the document d1 and query further increased  from 0.141 to 0.201 by adding two relavent terms to the document. As the number of relavent terms increase in the document, the similary between the document and query will increase."
      ]
    },
    {
      "metadata": {
        "id": "nywSPljxc-Eu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Relevance Feedback"
      ]
    },
    {
      "metadata": {
        "id": "8WNG_6w_doxt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The performance of the IR system can be improved by considering the user feedback and modifying the query based on the feedback"
      ]
    },
    {
      "metadata": {
        "id": "402ZDXltSrqE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Rocchio Relevance Feedback\n",
        "\n",
        "In this approach, if the user marks some of the documents retrieved as relevant (denoted by $D_r$) and some as non relavent (denoted by $D_n$), the query weights can be recalculated as below\n",
        "\n",
        "$\\overrightarrow{q} = \\alpha{\\overrightarrow{q}}+\\frac{\\beta}{|D_r|}\\displaystyle\\sum_{d_j \\epsilon D_r}\\overrightarrow{d_j} - \\frac{\\gamma}{|D_n|}\\displaystyle\\sum_{d_j \\epsilon D_n}\\overrightarrow{d_j}$\n",
        "\n",
        "$\\alpha, \\beta, \\gamma$  are the constants which can be tuned to increase/decrease the relavence of positive and negative feedback."
      ]
    },
    {
      "metadata": {
        "id": "VmYLhKNEgVoA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this question, user has given a feedback that document 3 is relavent which means the relavent documents set $D_r$ contain d2. However the user has not explicitly marked any non relavent documents and hence the non relavent document set $D_n$ will be empty. "
      ]
    },
    {
      "metadata": {
        "id": "03uE6adRilVM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Optimal values are $\\alpha, \\beta, \\gamma$ are usually 1, 0.75 and 0.15 respectively and I have used the same for the calculations, but these can be changed based on the IR system requirements."
      ]
    },
    {
      "metadata": {
        "id": "w9vIwoCUowcJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### New Query Weights"
      ]
    },
    {
      "metadata": {
        "id": "HxF5ja21DCno",
        "colab_type": "code",
        "outputId": "9884115a-0fb5-4bc9-86d5-0b643474cfb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "cell_type": "code",
      "source": [
        "qw_new = rocchio_rf(dw, qw, ['d3'], [])\n",
        "qw_new"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>truck</th>\n",
              "      <th>gold</th>\n",
              "      <th>fire</th>\n",
              "      <th>delivery</th>\n",
              "      <th>silver</th>\n",
              "      <th>arrived</th>\n",
              "      <th>shipment</th>\n",
              "      <th>damaged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>q</th>\n",
              "      <td>0.632068</td>\n",
              "      <td>0.632068</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.132068</td>\n",
              "      <td>0.132068</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      truck      gold  fire  delivery  silver   arrived  shipment  damaged\n",
              "q  0.632068  0.632068   0.0       0.0     0.5  0.132068  0.132068      0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "TT2zlCGqqcNr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the recalculated query weights, weight of the term in query is increased by 0.75 times the weight of document d3. "
      ]
    },
    {
      "metadata": {
        "id": "y1vR6iOnMQeU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### New Document Similarities"
      ]
    },
    {
      "metadata": {
        "id": "yh3d77E9o4_U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Document similarities are calculated based on new query weigts"
      ]
    },
    {
      "metadata": {
        "id": "Lb_LgYC4MUFP",
        "colab_type": "code",
        "outputId": "30239f5c-f375-4f8a-ac5d-79aa4f3f5563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Similarity of document d1 changed from {} to {}\".format(similarity(qw.loc[q_row], dw.loc['d1']), similarity(qw_new.loc[q_row], dw.loc['d1'])))\n",
        "print(\"Similarity of document d2 changed from {} to {}\".format(similarity(qw.loc[q_row], dw.loc['d2']), similarity(qw_new.loc[q_row], dw.loc['d2'])))\n",
        "print(\"Similarity of document d3 changed from {} to {}\".format(similarity(qw.loc[q_row], dw.loc['d3']), similarity(qw_new.loc[q_row], dw.loc['d3'])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity of document d1 changed from 0.14135252212346566 to 0.1796965371785806\n",
            "Similarity of document d2 changed from 0.5599663010899988 to 0.5201751026777683\n",
            "Similarity of document d3 changed from 0.5773502691896257 to 0.7339652844812885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s3BzELxIqwKD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After considering the user feedback that document d3 is relavent, and applying rocchio's relavence feedback method, the similarity score of document d3 has increased considerably. Similarity score of document d1 increased as well because of similarity between document d1 and d3 (i.e. term 'gold' with increased query weight because of d3 occur in document d1)."
      ]
    },
    {
      "metadata": {
        "id": "RDsSrkjHsFiI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Appendix (Code)"
      ]
    },
    {
      "metadata": {
        "id": "X4r1fjZR6B4j",
        "colab_type": "code",
        "outputId": "fe6e57e9-7039-47dd-e1c4-122453e157d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from math import log10, sqrt\n",
        "\n",
        "nltk.download('stopwords');\n",
        "nltk.download('punkt');\n",
        "\n",
        "d1 = \"Shipment of gold damaged in a fire\"\n",
        "d2 = \"Delivery of silver arrived in a silver truck\"\n",
        "d3 = \"Shipment of gold arrived in a truck\"\n",
        "coll = [d1, d2, d3]\n",
        "q = \"gold silver truck\"\n",
        "\n",
        "doc_list = ['d1', 'd2', 'd3']\n",
        "idf_row = 'idf'\n",
        "q_row = 'q'\n",
        "stopwords_eng = stopwords.words('english') + list(string.punctuation)\n",
        "unique_words = list(set([w.lower() for d in coll for w in nltk.word_tokenize(d) if w not in stopwords_eng]))\n",
        "\n",
        "def get_tf(coll):\n",
        "  tf = pd.DataFrame(0.0, columns=unique_words, index=doc_list)\n",
        "  for i, d in enumerate(coll):\n",
        "    for word in nltk.word_tokenize(d):\n",
        "      if word.lower() in unique_words:\n",
        "        tf.at[doc_list[i], word.lower()] += 1\n",
        "  return tf\n",
        "\n",
        "def get_idf(coll):  \n",
        "  N = len(coll)\n",
        "  idf = pd.DataFrame(columns=unique_words, index=[idf_row])\n",
        "  for col in tf.columns:\n",
        "    n = len([c for c in tf[col] if c > 0.0])\n",
        "    idf.at[idf_row, col] = log10(N/n)\n",
        "  return idf\n",
        "\n",
        "def normalise_tf(tf):\n",
        "  tf_norm = tf.copy()\n",
        "  for row in tf.index:\n",
        "    for col in tf.columns:\n",
        "      if tf.at[row, col] > 0:\n",
        "        tf_norm.at[row, col] = 1 + log10(tf.at[row, col])\n",
        "  return tf_norm\n",
        "      \n",
        "def get_weights(tf, idf):\n",
        "  dw = pd.DataFrame(0.0, columns=unique_words, index=doc_list)\n",
        "  for row in doc_list:\n",
        "    for col in unique_words:\n",
        "      dw.at[row, col] = tf.at[row, col] * idf.at[idf_row, col]\n",
        "  return dw\n",
        "    \n",
        "def get_query_weights(q, idf):\n",
        "  q_words = [w for w in q.split(\" \") if w not in stopwords_eng]\n",
        "  qw = pd.DataFrame(0.0, columns=unique_words, index=[q_row])\n",
        "  for word in q_words:\n",
        "    qw.at[q_row, word] = 0.5\n",
        "  return qw\n",
        "  \n",
        "def similarity(q, d):\n",
        "  dot = np.dot(d, q)\n",
        "  dl = np.linalg.norm(d)\n",
        "  ql = np.linalg.norm(q)\n",
        "  print(dot)\n",
        "  print(dl)\n",
        "  print(ql)\n",
        "  return dot/(dl*ql)\n",
        "  \n",
        "def recalculate_similarity(coll, doc):\n",
        "  tf = get_tf(coll)\n",
        "  tf_norm = normalise_tf(tf)\n",
        "  dw = get_weights(tf_norm, idf)\n",
        "  return (similarity(qw.loc[q_row], dw.loc[doc]))\n",
        "  \n",
        "def rocchio_rf(dw, qw, dr, dn):\n",
        "  alpha = 1\n",
        "  beta = 0.75\n",
        "  gamma = 0.15\n",
        "  if len(dr) > 0:\n",
        "    centroid_dr = np.mean(dw.loc[dr])\n",
        "  else:\n",
        "    centroid_dr = np.zeros(len(dw.columns))\n",
        "  if len(dn) > 0:\n",
        "    centroid_dn = np.mean(dw.loc[dn])\n",
        "  else:\n",
        "    centroid_dn = np.zeros(len(dw.columns))\n",
        "  qw_new = alpha*qw.loc[q_row] + beta*centroid_dr - gamma*centroid_dn\n",
        "  qw_new = pd.DataFrame(qw_new, columns=['q']).transpose()\n",
        "  return qw_new\n",
        "  \n",
        "tf = get_tf(coll)\n",
        "idf = get_idf(coll)\n",
        "tf_norm = normalise_tf(tf)\n",
        "dw = get_weights(tf_norm, idf)\n",
        "qw = get_query_weights(q, idf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SC_49kLVY1py",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Improvements"
      ]
    },
    {
      "metadata": {
        "id": "HIm2OzXQY31e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In classic Rocchio's relavence feedback algorithm, we modify the query weights using a set of relavent documents and non relavent documents identified by the user. If the user marks some of the documents retrieved as relevant (denoted by $D_r$) and some as non relavent (denoted by $D_n$), the query weights can be recalculated as below\n",
        "\n",
        "$\\overrightarrow{q} = \\alpha{\\overrightarrow{q}}+\\frac{\\beta}{|D_r|}\\displaystyle\\sum_{d_j \\epsilon D_r}\\overrightarrow{d_j} - \\frac{\\gamma}{|D_n|}\\displaystyle\\sum_{d_j \\epsilon D_n}\\overrightarrow{d_j}$\n",
        "\n",
        "$\\alpha, \\beta, \\gamma$  are the constants which can be tuned to increase/decrease the relavence of positive and negative feedback.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "t5zhlUuOaCY_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If the user instead of identifying the relavent and non relavent documents, user give a feedback ranging from 1 to 5 where 1 means very non relavent and 5 means very relavent, we can modify the Rocchio's algorithm to take this into account. Similar to classic algorithm, we can calculate the centroids of all the documents in each group and multiply it with a weight assigned to each group. These weights can vary from a range of -1 to 1. Documents in very non relevant category can be given a more negative weight and documents in very relavent category can be give more positive weight. Finally adding all these to query weights will give a query point placed closer to relavent documents  and away from non relavent points.\n",
        "\n",
        "The algorithm can be modified as below:\n",
        "\n",
        "$\\overrightarrow{q} = k_0{\\overrightarrow{q}}+\\frac{k_1}{|D_1|}\\displaystyle\\sum_{d_j \\epsilon D_1}\\overrightarrow{d_j} +\\frac{k_2}{|D_2|}\\displaystyle\\sum_{d_j \\epsilon D_2}\\overrightarrow{d_j} +\\frac{k_3}{|D_3|}\\displaystyle\\sum_{d_j \\epsilon D_3}\\overrightarrow{d_j} +\\frac{k_4}{|D_4|}\\displaystyle\\sum_{d_j \\epsilon D_4}\\overrightarrow{d_j} +\\frac{k_5}{|D_5|}\\displaystyle\\sum_{d_j \\epsilon D_5}\\overrightarrow{d_j} $\n",
        "\n",
        "* $k_0$ is the constant to multiply with query\n",
        "\n",
        "* $k_1, k_2, k_3, k_4, k_5 $ are the constant multiplier to each group of documents in the feedback set.\n",
        "\n",
        "* $k_1, k_2$ will be negative numbers as they represent constant multipliers for non relavent documents and in general $k_1$ will be larger than $k_2$.\n",
        "\n",
        "* $k_4, k_5$ will be positive numbers as they represent constant multipliers for relavent documents and in general $k_5$ will be larger than $k_4$.\n",
        "\n",
        "* These constants can be varied to tune the performance of the relavence feedback algorithm.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "KWaywcGZfUBx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A typical IR systems which retrieves relevant documents can be improvised by suggesting additional query terms to the user. This can be done at global and local level. Below are some of the techniques I included query expansion or query refinement"
      ]
    },
    {
      "metadata": {
        "id": "imuRBguzz2Pg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Global Query Expansion Techniques\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.   **Spelling check**: A word dictionary can be built with all the known words in the collection and the words in the WordNet. This can be used to find the correct word and suggest it to the user. Correct words can be identified using methods like edit distance, Linear interpolation using trigram probabilities, named entity recognition, parts of speech tagging etc. \n",
        "2.   **Manual Thesaurus building**: A manual Thesaurus can be built by collecting the word synonyms. Also different domains (like Law, Medical) have different set of vocabulary and domain experts can build a Thesaurus with all the relevant words. Individual query terms can be compared with this Thesaurus and most relevant words can be identifying by using weighting schemes. Top N relevant words can be suggested to the user for adding it to the query.\n",
        "3. **Co-occuring words**: Noun groups (one or more continous noun words) can be extracted from the entire collection to build a collection of frequently occuring pairs of words. The terms in the query are matched with this co-occuring words collection and the relevant ones are extract. Weighting schemes can be used to rank these co-occured words extracted and can be used for suggesting the user. \n",
        "4. **Identifying Symantics**: Grammer analysis can be done on the collection to extract the gramatical relations between words and can be suggested to the users.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1sEmlsRoz6Re",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Automatic Query Expansion\n",
        "\n",
        "#### Pseudo Relevance Feedback method\n",
        "\n",
        "In this method, instead of getting the relevance feedback from the user, we assume that top N documents retrieved are relevant. Query weights can be recalculated using Rocchio's menthods using these top N documents and the new set of relevant documents are extracted using the recalculated query weights. In this method query weights are modified but the query is not expanded. This can improve the performance of IR model by improving the precision and recall.\n",
        "\n",
        "#### Local Context Analysis\n",
        "\n",
        "In this method, we take the co-occuring words that is build in the global analysis. Top N co-occuring words are extracted fro the query terms and using these, top N ranked passages are retrieved (passages are used instead of documents to improve the performance and reduce processing non relevant parts of the documents). From these top N passages, top M co-occuring words are extracted and are added to the query. This improves the performance of the IR system whilse reducing the processing time."
      ]
    },
    {
      "metadata": {
        "id": "RpNTMqpP0C1_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The above methods can be used to suggest the user with additional query terms and sometimes automatically add query terms to the search."
      ]
    },
    {
      "metadata": {
        "id": "IpbcPoMB0GLz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Limitations of Vector Space Model"
      ]
    },
    {
      "metadata": {
        "id": "QU5vEJey0M-h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the term frequency, term-term correlation and other techniques for calculating the similarity, we have made some assumptions or ignored some of the parameters which gives more information about information needs. Some of them are stated below:\n",
        "\n",
        "* The basic assumption we made in using the term frequency, correlations is that the terms are independent. In both Vector Space model and Probabilistic model, the underlying assumption is that the terms are independent. However this assumption is not true as group of words in a document are dependent on the context of the passage or document.\n",
        "* Order of the words are not considered. The query words and document words are considered individually and the IR model is designed ignoring the sequence of words. \n",
        "\n",
        "Some of the below methods can be used to build models which capture above mentioned points"
      ]
    },
    {
      "metadata": {
        "id": "_tKqm_6M0OQf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Word Similarity\n",
        "\n",
        "\n",
        "\n",
        "1.   As a first step, we extract the words to be compared. We usually extract all the Nouns and Verbs.\n",
        "2.   We then calculated the distance between each meaning in the synset of the two words.\n",
        "3. The shortest path distance between the two words is calculated and meaning is captured\n",
        "4. Related Hyponyms are extracted to give additional query terms based on the context of the query \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_8VjxjdA0UVp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sentence Similarity\n",
        "\n",
        "\n",
        "* Word similarity along with the domain specific words dictionary, we can calculate the sentence similarity. Sementic vectors are build based on the above synsets and hyponyms and then the similarity between the sentences are calculated which captures the semantic of the sentence rather than term frequencies.\n",
        "* In traditional IR systems, because the terms are assumed as independent, a sentence with same words and different are is given same similarity score. The **word order similarity** can be used in this case to improve th performance of the IR model.\n"
      ]
    },
    {
      "metadata": {
        "id": "vgHeKXit0cvb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Grouping of Documents\n",
        "\n",
        "One of the drawbacks of the traditional IR model is that it considers all the documents are in a single cluster. This can provide challenges like query drifting away by automatic query expantion. One of the methods to improve in this aspect is to group the documents into different clusters and perform the search / extract the relavent documents based on the cluster the user is targetting. K-Means clustering technique can be used for creating the clusters."
      ]
    }
  ]
}